# import json
# import time
# import traceback
# from pathlib import Path
# from typing import Any, Dict, List, Optional, Tuple

# from src.query import Query
# from src.generate import generate

# # =========================
# # Config
# # =========================
# MODEL_NAME = "Qwen/Qwen3-30B-A3B-Instruct-2507"

# K_RETRIEVAL = 20   # FAISSì—ì„œ ë½‘ëŠ” í›„ë³´ chunk ìˆ˜
# K_CONTEXT   = 5    # LLM í”„ë¡¬í”„íŠ¸ì— ì‹¤ì œë¡œ ë„£ëŠ” chunk ìˆ˜

# INPUT_JSONL  = "3gpp_rag_eval_qa_100.jsonl"
# OUTPUT_JSONL = "3gpp_rag_eval_qa_100_open_answers.jsonl"


# # =========================
# # Core pipeline (open-ended)
# # =========================
# def build_query_obj(user_query: str) -> Query:
#     """
#     Query ê°ì²´ ìƒì„± -> Terms/Definitions í™•ì¥ -> 3GPP retrieval ìˆ˜í–‰.
#     """
#     q = Query(user_query, [])

#     # def_TA_question()ì€ self.queryë¥¼ ì“°ë¯€ë¡œ ë¨¼ì € ì„¸íŒ…
#     q.query = q.question

#     # Terms/Definitions, Abbrev í™•ì¥
#     q.def_TA_question()

#     # ì›ë˜ ì§ˆë¬¸ í…ìŠ¤íŠ¸ë„ í™•ì¥ëœ ì§ˆë¬¸ìœ¼ë¡œ overwrite (ë„¤ pipeline ë°©ì‹)
#     q.question = q.enhanced_query

#     # 3GPP context retrieval (validator off)
#     q.get_3GPP_context(k=K_RETRIEVAL, model_name=MODEL_NAME, validate_flag=False)

#     return q


# def slice_context_for_llm(q: Query) -> List[str]:
#     """
#     retrieval ê²°ê³¼(context)ê°€ listì´ë©´ ìƒìœ„ K_CONTEXTë§Œ LLMì— ë„£ë„ë¡ ìŠ¬ë¼ì´ìŠ¤.
#     """
#     ctx = getattr(q, "context", None)

#     if isinstance(ctx, list):
#         q.context = ctx[:K_CONTEXT]
#         return q.context

#     if isinstance(ctx, str) and ctx.strip():
#         q.context = [ctx]
#         return q.context

#     q.context = []
#     return q.context


# def answer_one_open(question_text: str) -> Dict[str, Any]:
#     """
#     1ê°œ ì§ˆë¬¸ì— ëŒ€í•´ open-ended ë‹µ ìƒì„±.
#     """
#     start = time.time()

#     qobj = build_query_obj(question_text)
#     context_used = slice_context_for_llm(qobj)  # âœ… LLMì— ë“¤ì–´ê°ˆ ì»¨í…ìŠ¤íŠ¸ 5ê°œë§Œ ìœ ì§€

#     # generate()ëŠ” question.contextë¥¼ ê¸°ë°˜ìœ¼ë¡œ promptë¥¼ ë§Œë“¤ê¸° ë•Œë¬¸ì—,
#     # ìœ„ì—ì„œ qobj.contextë¥¼ 5ê°œë¡œ ì¤„ì˜€ìœ¼ë©´ LLM ì…ë ¥ë„ 5ê°œë§Œ ë“¤ì–´ê°.
#     answer_str, context_str, _ = generate(qobj, MODEL_NAME)

#     return {
#         "question": question_text,
#         "model": MODEL_NAME,
#         "k_retrieval": K_RETRIEVAL,
#         "k_context": K_CONTEXT,
#         "answer": answer_str,              # âœ… ìƒì„±ëœ ì£¼ê´€ì‹ ë‹µë³€
#         "context_used": context_used,      # âœ… ì‹¤ì œ LLMì— ë„£ì€ chunk 5ê°œ(ë¦¬ìŠ¤íŠ¸)
#         "elapsed_sec": round(time.time() - start, 4),
#     }


# # =========================
# # JSONL runner
# # =========================
# def run_jsonl(
#     input_path: str = INPUT_JSONL,
#     output_path: str = OUTPUT_JSONL,
#     resume_append: bool = True,
# ) -> None:
#     """
#     INPUT_JSONLì—ì„œ question ì½ì–´ open-ended ë‹µ ìƒì„± í›„ OUTPUT_JSONLë¡œ ì €ì¥.
#     """
#     in_path = Path(input_path)
#     out_path = Path(output_path)

#     if not in_path.exists():
#         raise FileNotFoundError(f"Input jsonl not found: {in_path.resolve()}")

#     out_mode = "a" if resume_append else "w"

#     with in_path.open("r", encoding="utf-8") as fin, out_path.open(out_mode, encoding="utf-8") as fout:
#         for idx, line in enumerate(fin, start=1):
#             line = line.strip()
#             if not line:
#                 continue

#             # 1) parse json
#             try:
#                 item = json.loads(line)
#             except Exception:
#                 fout.write(json.dumps({
#                     "line": idx,
#                     "error": "json_parse_failed",
#                     "raw": line[:500]
#                 }, ensure_ascii=False) + "\n")
#                 fout.flush()
#                 continue

#             # 2) read question
#             q = item.get("question")
#             if not isinstance(q, str) or not q.strip():
#                 fout.write(json.dumps({
#                     "line": idx,
#                     "error": "missing_question",
#                     "keys": list(item.keys())
#                 }, ensure_ascii=False) + "\n")
#                 fout.flush()
#                 continue

#             question_text = q.strip()

#             # 3) generate answer
#             try:
#                 result = answer_one_open(question_text)

#                 # ì›ë³¸ ë©”íƒ€ë¥¼ ê°™ì´ ë‚¨ê¸°ê³  ì‹¶ìœ¼ë©´ keep (ì •ë‹µ/ì˜µì…˜ì€ "ì°¸ê³ ìš©"ìœ¼ë¡œë§Œ ë³´ì¡´)
#                 for keep_key in ("category", "difficulty", "source", "answer", "options", "explanation"):
#                     if keep_key in item:
#                         result[keep_key] = item[keep_key]

#                 fout.write(json.dumps(result, ensure_ascii=False) + "\n")
#                 fout.flush()

#                 print(f"[{idx}] DONE | {question_text[:90]}")

#             except Exception as e:
#                 fout.write(json.dumps({
#                     "line": idx,
#                     "question": question_text[:300],
#                     "error": str(e),
#                     "traceback": traceback.format_exc()[-4000:],
#                 }, ensure_ascii=False) + "\n")
#                 fout.flush()

#                 print(f"[{idx}] ERROR: {e}")

#     print(f"\nâœ… Saved results to: {out_path.resolve()}")


# # =========================
# # Entry
# # =========================
# if __name__ == "__main__":
#     run_jsonl()

### reranker ì¶”ê°€ëœ ì½”ë“œìš© ###
import json
import time
import traceback
from pathlib import Path
from typing import Dict, Any

# âœ… ë„¤ pipeline ê·¸ëŒ€ë¡œ import
from pipeline_offline_addreranker import TelcoRAG, GEN_MODEL


INPUT_JSONL  = "3gpp_rag_eval_qa_100.jsonl"
OUTPUT_JSONL = "3gpp_rag_eval_qa_100_answers_reranker.jsonl"


def answer_one_open(item: Dict[str, Any]) -> Dict[str, Any]:
    """
    addreranker ê¸°ë°˜ ì£¼ê´€ì‹ ë‹µì•ˆ ìƒì„±
    """
    question = item["question"].strip()
    start = time.time()

    # ğŸ”´ í•µì‹¬: answer / options ì ˆëŒ€ ë„˜ê¸°ì§€ ì•ŠëŠ”ë‹¤
    answer, context_used = TelcoRAG(
        query=question,
        answer=None,
        options=None,
        model_name=GEN_MODEL,
    )

    elapsed = round(time.time() - start, 4)

    result = {
        "question": question,
        "answer": answer,
        "context_used": context_used,   # rerank top-5
    }

    # ì›ë³¸ ë©”íƒ€ ë³´ì¡´ (ìˆìœ¼ë©´)
    for k in ["category", "difficulty", "source"]:
        if k in item:
            result[k] = item[k]

    return result


def main():
    in_path = Path(INPUT_JSONL)
    out_path = Path(OUTPUT_JSONL)

    if not in_path.exists():
        raise FileNotFoundError(in_path.resolve())

    with in_path.open("r", encoding="utf-8") as fin, \
         out_path.open("a", encoding="utf-8") as fout:

        for idx, line in enumerate(fin, start=1):
            line = line.strip()
            if not line:
                continue

            try:
                item = json.loads(line)
            except Exception:
                fout.write(json.dumps({
                    "line": idx,
                    "error": "json_parse_failed",
                    "raw": line[:300],
                }, ensure_ascii=False) + "\n")
                fout.flush()
                continue

            if "question" not in item or not isinstance(item["question"], str):
                fout.write(json.dumps({
                    "line": idx,
                    "error": "missing_question",
                    "keys": list(item.keys()),
                }, ensure_ascii=False) + "\n")
                fout.flush()
                continue

            try:
                result = answer_one_open(item)
                fout.write(json.dumps(result, ensure_ascii=False) + "\n")
                fout.flush()
                print(f"[{idx}] DONE | {item['question'][:80]}")

            except Exception as e:
                fout.write(json.dumps({
                    "line": idx,
                    "question": item.get("question", "")[:300],
                    "error": str(e),
                    "traceback": traceback.format_exc()[-4000:],
                }, ensure_ascii=False) + "\n")
                fout.flush()
                print(f"[{idx}] ERROR: {e}")

    print(f"\nâœ… Saved results to: {out_path.resolve()}")


if __name__ == "__main__":
    main()
